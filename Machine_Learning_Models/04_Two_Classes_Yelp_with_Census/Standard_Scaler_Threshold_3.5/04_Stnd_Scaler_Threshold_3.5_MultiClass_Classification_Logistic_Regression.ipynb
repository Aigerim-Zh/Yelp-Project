{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a6835e",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "24b3f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "# from config import db_password\n",
    "from sqlalchemy import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "business_df = pd.read_csv(\"../../../Data/new_merged_datasets.csv\")\n",
    "#business_df = pd.read_csv(\"../../../Data/merged_datasets.csv\")\n",
    "\n",
    "# Categorizing restaurants based on stars ratings\n",
    "business_df[\"Category\"] = pd.cut(business_df[\"Stars_Rating\"],bins=[0.9,3.5,5],\n",
    "                                 labels=[\"Lower Performance\", \"Higher Performance\"])\n",
    "\n",
    "def changeStatus(status):\n",
    "    if status == \"Lower Performance\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "business_df['Category_Encoded'] = business_df[\"Category\"].apply(changeStatus)\n",
    "business_df[\"Category_Encoded\"] = pd.to_numeric(business_df[\"Category_Encoded\"])\n",
    "\n",
    "business_df[\"Median_Income(dollars)\"] = pd.to_numeric(business_df[\"Median_Income(dollars)\"], errors='coerce')\n",
    "business_df[\"Mean_Income(dollars)\"] = pd.to_numeric(business_df[\"Mean_Income(dollars)\"], errors='coerce')\n",
    "\n",
    "business_df = business_df.dropna(subset=['Median_Income(dollars)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "126c1ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Higher Performance    8096\n",
       "Lower Performance     7511\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "90d85246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15607.000000\n",
       "mean         3.668931\n",
       "std          0.694275\n",
       "min          1.000000\n",
       "25%          3.500000\n",
       "50%          4.000000\n",
       "75%          4.000000\n",
       "max          5.000000\n",
       "Name: Stars_Rating, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df[\"Stars_Rating\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "01c84332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Restaurant_ID', 'Restaurants_Name', 'Address', 'City',\n",
       "       'State', 'Postal_Code', 'Latitude', 'Longitude', 'Stars_Rating',\n",
       "       'Review_Count', 'Restaurants_Delivery', 'Outdoor_Seating',\n",
       "       'Accepts_CreditCards', 'Price_Range', 'Alcohol', 'Good_For_Kids',\n",
       "       'Reservations', 'Restaurants_TakeOut', 'WiFi', 'Good_For_Groups',\n",
       "       'Wheelchair_Accessible', 'Happy_Hour', 'Noise_Level',\n",
       "       'Dietary_Restrictions', 'Total_Estimate_Households_per_Zip',\n",
       "       'Total_Estimate_Married-couple_Family_households',\n",
       "       'Total_Estimate_Nonfamily_households', 'Median_Income(dollars)',\n",
       "       'Mean_Income(dollars)', 'Population', 'Category', 'Category_Encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7526ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set\n",
    "X = business_df[['Review_Count', 'Restaurants_Delivery', 'Outdoor_Seating',\n",
    "       'Accepts_CreditCards', 'Price_Range', 'Alcohol', 'Good_For_Kids',\n",
    "       'Reservations', 'Restaurants_TakeOut', 'WiFi', 'Good_For_Groups',\n",
    "       'Wheelchair_Accessible', 'Happy_Hour', 'Noise_Level',\n",
    "       'Dietary_Restrictions',\n",
    "                'Total_Estimate_Married-couple_Family_households',\n",
    "       'Total_Estimate_Nonfamily_households',\n",
    "                'Median_Income(dollars)', 'Population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "276df36e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 8096, 0: 7511})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the target\n",
    "y = business_df[\"Category_Encoded\"]\n",
    "y\n",
    "from collections import Counter\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ffeb627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the model into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y, \n",
    "                                                   random_state=1, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ce93a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the Training and Testing Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instantiate a StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the Standard Scaler with the training data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "\n",
    "# Scaling the data \n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d7ed0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver=\"lbfgs\", random_state=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9002e287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "121a1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "84bf815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.589185033316248"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "253cfe0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1256  622]\n",
      " [ 981 1043]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "matrix=confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a50f969d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.67      0.61      1878\n",
      "           1       0.63      0.52      0.57      2024\n",
      "\n",
      "    accuracy                           0.59      3902\n",
      "   macro avg       0.59      0.59      0.59      3902\n",
      "weighted avg       0.60      0.59      0.59      3902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report=classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c3665",
   "metadata": {},
   "source": [
    "# Logistic Regression with Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed5b07b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 11961, 0: 3646})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2862c179",
   "metadata": {},
   "source": [
    "It seems like the classes are unbalanced, which might bias the results toward the majority classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3a60c",
   "metadata": {},
   "source": [
    "# Naive Random Oversampling\n",
    "\n",
    "\n",
    "In random oversampling, instances of the minority class are randomly selected and added to the training set until the majority and minority classes are balanced.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75e1e177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Higher Performance': 14184, 'Lower Performance': 14184})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6fcc08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "842718d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6154329570174318"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e065ff0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6146207225742006"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "balanced_accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4c21ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2210, 2519],\n",
       "       [ 345, 1114]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "286aeabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "Higher Performance       0.86      0.47      0.76      0.61      0.60      0.35      4729\n",
      " Lower Performance       0.31      0.76      0.47      0.44      0.60      0.37      1459\n",
      "\n",
      "       avg / total       0.73      0.54      0.69      0.57      0.60      0.35      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538a78a",
   "metadata": {},
   "source": [
    "# SMOTE Oversampling\n",
    "\n",
    "In SMOTE, like naive random oversampling, the size of the minority is increased. The key difference with random oversampling is how the minority class is increased in size. \n",
    "\n",
    "However, in SMOTE, new instances are interpolated. That is, for an instance from the minority class, new values are generated based on its distance from its neighbors.\n",
    "\n",
    "**Random oversampling draws from existing observations, whereas SMOTE generates synthetic observations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "421dbc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Higher Performance': 14184, 'Lower Performance': 14184})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy=\"auto\").fit_resample(X_train, y_train)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c56c6adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc37cd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.617285090420315"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a918a61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2234, 2495],\n",
       "       [ 347, 1112]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a80c7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "Higher Performance       0.87      0.47      0.76      0.61      0.60      0.35      4729\n",
      " Lower Performance       0.31      0.76      0.47      0.44      0.60      0.37      1459\n",
      "\n",
      "       avg / total       0.73      0.54      0.69      0.57      0.60      0.35      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43caaffc",
   "metadata": {},
   "source": [
    "# Cluster Centroids Undersampling\n",
    "\n",
    "Akin to SMOTE, the algorithm identifies clusters of the majority class, then generates synthetic data points, called centroids, that are representative of the clusters. The majority class is then undersampled down to the size of the minority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "426875d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Higher Performance': 4377, 'Lower Performance': 4377})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11903644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2547c908",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92c1c37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6025434622328708"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2223000f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1751, 2978],\n",
       "       [ 241, 1218]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "955c2120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "Higher Performance       0.88      0.37      0.83      0.52      0.56      0.29      4729\n",
      " Lower Performance       0.29      0.83      0.37      0.43      0.56      0.32      1459\n",
      "\n",
      "       avg / total       0.74      0.48      0.73      0.50      0.56      0.30      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224649e",
   "metadata": {},
   "source": [
    "# Combination of Over and Under-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0cf9bb",
   "metadata": {},
   "source": [
    "A downside of oversampling with SMOTE is its reliance on the immediate neighbors of a data point. Because the algorithm doesn't see the overall distribution of data, the new data it creates can be heavily influenced by outliers. \n",
    "\n",
    "A downside of undersampling is that it involves loss of data and is not an option when the dataset is small. \n",
    "\n",
    "SMOTEEN combines the SMOTE and Edited Nearest Neighbors (ENN) algorithms. It includes the following steps: \n",
    "1. Oversample the minority class with SMOTE.\n",
    "2. Clean the resulting data with an undersampling strategy. If the two of the nearest neighbors of a data point belong to different classes, the data point is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ab57e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Average': 3310, 'Good': 1184, 'Poor': 6738, 'Successful': 2781})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "sm = SMOTEENN(random_state=1)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e65af67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f60fcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28698953796394144"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0544ca93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3,    4, 1127,   71],\n",
       "       [  31,   35, 2881,  560],\n",
       "       [   0,    0,  251,    3],\n",
       "       [   6,   13, 1023,  180]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45056e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "    Average       0.07      0.00      0.99      0.00      0.05      0.00      1205\n",
      "       Good       0.67      0.01      0.99      0.02      0.10      0.01      3507\n",
      "       Poor       0.05      0.99      0.15      0.09      0.39      0.16       254\n",
      " Successful       0.22      0.15      0.87      0.18      0.36      0.12      1222\n",
      "\n",
      "avg / total       0.44      0.08      0.93      0.05      0.15      0.04      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c61e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a6835e",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "24b3f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "# from config import db_password\n",
    "from sqlalchemy import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "business_df = pd.read_csv(\"../../../Data/business_census_merged_dataset.csv\")\n",
    "\n",
    "# Categorizing restaurants based on stars ratings\n",
    "business_df[\"Category\"] = pd.cut(business_df[\"Stars_Rating\"],bins=[0.9,3,5],\n",
    "                                 labels=[\"Lower Performance\", \"Higher Performance\"])\n",
    "\n",
    "\n",
    "def changeStatus(status):\n",
    "    if status == \"Lower Performance\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "business_df['Category_Encoded'] = business_df[\"Category\"].apply(changeStatus)\n",
    "business_df[\"Category_Encoded\"] = pd.to_numeric(business_df[\"Category_Encoded\"])\n",
    "\n",
    "business_df[\"Median_Income(dollars)\"] = pd.to_numeric(business_df[\"Median_Income(dollars)\"], errors='coerce')\n",
    "business_df[\"Mean_Income(dollars)\"] = pd.to_numeric(business_df[\"Mean_Income(dollars)\"], errors='coerce')\n",
    "\n",
    "business_df = business_df.dropna(subset=['Median_Income(dollars)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "49e6c291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Higher Performance': 18905, 'Lower Performance': 5834})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = business_df[\"Category\"]\n",
    "from collections import Counter\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "01c84332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Restaurant_ID', 'Restaurants_Name', 'Address', 'City', 'State',\n",
       "       'Postal_Code', 'Latitude', 'Longitude', 'Stars_Rating', 'Review_Count',\n",
       "       'Restaurants_Delivery', 'Outdoor_Seating', 'Accepts_CreditCards',\n",
       "       'Price_Range', 'Alcohol', 'Good_For_Kids', 'Reservations',\n",
       "       'Restaurants_TakeOut', 'WiFi', 'Good_For_Groups',\n",
       "       'Wheelchair_Accessible', 'Happy_Hour', 'Noise_Level',\n",
       "       'Dietary_Restrictions', 'Total_Estimate_Households_per_Zip',\n",
       "       'Total_Estimate_Married-couple_Family_households',\n",
       "       'Total_Estimate_Nonfamily_households', 'Median_Income(dollars)',\n",
       "       'Mean_Income(dollars)', 'Category', 'Category_Encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7526ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set\n",
    "X = business_df[['Review_Count', 'Restaurants_Delivery', 'Outdoor_Seating',\n",
    "       'Accepts_CreditCards', 'Price_Range', 'Alcohol', 'Good_For_Kids',\n",
    "       'Reservations', 'Restaurants_TakeOut', 'WiFi', 'Good_For_Groups',\n",
    "       'Wheelchair_Accessible', 'Happy_Hour', 'Noise_Level',\n",
    "       'Dietary_Restrictions',\n",
    "                'Total_Estimate_Married-couple_Family_households',\n",
    "       'Total_Estimate_Nonfamily_households',\n",
    "                'Median_Income(dollars)','Total_Estimate_Households_per_Zip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "276df36e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "24734    1\n",
       "24735    1\n",
       "24736    0\n",
       "24737    1\n",
       "24738    0\n",
       "Name: Category_Encoded, Length: 24739, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the target\n",
    "y = business_df[\"Category_Encoded\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6ffeb627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the model into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y, \n",
    "                                                   random_state=1, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9d7ed0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver=\"lbfgs\", random_state=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9002e287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "121a1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "93606206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76410670978173"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "84bf815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7642017893715641"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_train = model.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "253cfe0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1459]\n",
      " [   0 4726]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "matrix=confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a50f969d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1459\n",
      "           1       0.76      1.00      0.87      4726\n",
      "\n",
      "    accuracy                           0.76      6185\n",
      "   macro avg       0.38      0.50      0.43      6185\n",
      "weighted avg       0.58      0.76      0.66      6185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/apple/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/apple/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report=classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c3665",
   "metadata": {},
   "source": [
    "# Logistic Regression with Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ed5b07b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 18905, 0: 5834})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2862c179",
   "metadata": {},
   "source": [
    "It seems like the classes are unbalanced, which might bias the results toward the majority classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3a60c",
   "metadata": {},
   "source": [
    "# Naive Random Oversampling\n",
    "\n",
    "\n",
    "In random oversampling, instances of the minority class are randomly selected and added to the training set until the majority and minority classes are balanced.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "75e1e177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 14179, 1: 14179})"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c6fcc08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "842718d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6024690387592357"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e065ff0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6194546462071675"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "balanced_accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c4c21ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1085,  374],\n",
       "       [2546, 2180]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "286aeabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.30      0.74      0.46      0.43      0.59      0.35      1459\n",
      "          1       0.85      0.46      0.74      0.60      0.59      0.33      4726\n",
      "\n",
      "avg / total       0.72      0.53      0.68      0.56      0.59      0.34      6185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538a78a",
   "metadata": {},
   "source": [
    "# SMOTE Oversampling\n",
    "\n",
    "In SMOTE, like naive random oversampling, the size of the minority is increased. The key difference with random oversampling is how the minority class is increased in size. \n",
    "\n",
    "However, in SMOTE, new instances are interpolated. That is, for an instance from the minority class, new values are generated based on its distance from its neighbors.\n",
    "\n",
    "**Random oversampling draws from existing observations, whereas SMOTE generates synthetic observations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "421dbc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 14179, 1: 14179})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy=\"auto\").fit_resample(X_train, y_train)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c56c6adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fc37cd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6029358104453018"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d0c98f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6203868739483945"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "balanced_accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a918a61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1070,  389],\n",
       "       [2493, 2233]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8a80c7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.30      0.73      0.47      0.43      0.59      0.36      1459\n",
      "          1       0.85      0.47      0.73      0.61      0.59      0.34      4726\n",
      "\n",
      "avg / total       0.72      0.53      0.67      0.56      0.59      0.34      6185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43caaffc",
   "metadata": {},
   "source": [
    "# Cluster Centroids Undersampling\n",
    "\n",
    "Akin to SMOTE, the algorithm identifies clusters of the majority class, then generates synthetic data points, called centroids, that are representative of the clusters. The majority class is then undersampled down to the size of the minority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "426875d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4375, 1: 4375})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "11903644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2547c908",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "92c1c37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5980266224467509"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fd87ae9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47606985016707987"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2223000f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1223,  236],\n",
       "       [3035, 1691]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "955c2120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.29      0.84      0.36      0.43      0.55      0.31      1459\n",
      "          1       0.88      0.36      0.84      0.51      0.55      0.29      4726\n",
      "\n",
      "avg / total       0.74      0.47      0.72      0.49      0.55      0.29      6185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224649e",
   "metadata": {},
   "source": [
    "# Combination of Over and Under-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0cf9bb",
   "metadata": {},
   "source": [
    "A downside of oversampling with SMOTE is its reliance on the immediate neighbors of a data point. Because the algorithm doesn't see the overall distribution of data, the new data it creates can be heavily influenced by outliers. \n",
    "\n",
    "A downside of undersampling is that it involves loss of data and is not an option when the dataset is small. \n",
    "\n",
    "SMOTEEN combines the SMOTE and Edited Nearest Neighbors (ENN) algorithms. It includes the following steps: \n",
    "1. Oversample the minority class with SMOTE.\n",
    "2. Clean the resulting data with an undersampling strategy. If the two of the nearest neighbors of a data point belong to different classes, the data point is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0ab57e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 7176, 1: 5616})"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "sm = SMOTEENN(random_state=1)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e65af67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3f60fcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6029112282483815"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "af5cdc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61665957502544"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "balanced_accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0544ca93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1161,  298],\n",
       "       [2788, 1938]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "45056e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.29      0.80      0.41      0.43      0.57      0.34      1459\n",
      "          1       0.87      0.41      0.80      0.56      0.57      0.31      4726\n",
      "\n",
      "avg / total       0.73      0.50      0.70      0.53      0.57      0.32      6185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c61e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
